# params.yaml

# This list is used by DVC to loop through data splits.
data_splits:
  - train
  - validation
  - test

# =================================================================
# --- HYPERPARAMETERS FOR GOLD PIPELINE STAGES ---
# =================================================================
gold_pipeline:
  imputation:
    median: ["price", "time", "distance"]
    mode: ["agency", "flight_type"]
    constant:
      from_location: "Unknown"
      to_location: "Unknown"
  rare_category_grouping:
    cardinality_threshold: 0.01
  outlier_handling:
    detection_strategy: "iqr"
    handling_strategy: "trim"
  power_transformer:
    strategy: "yeo-johnson"
  scaler:
    strategy: "standard"

# =================================================================
# --- PARAMETERS FOR MLFLOW ---
# =================================================================
mlflow_params:
  experiment_name: "Model_Bake_Off"

# =================================================================
# --- PARAMETERS FOR MODEL TRAINING ---
# =================================================================
training_pipeline:
  # -----------------------------------------------------------------
  # >> The ONLY line you need to change to run a different model <<
  # This key points to one of the configurations in the 'models' dictionary below.
  model_config_to_run: "RandomForestRegressor"
  # -----------------------------------------------------------------

  # --- Dictionary of all available model configurations ---
  models:
    # =================================================================
    # 1. Linear Models
    # =================================================================
    LinearRegression:
      model_class: "LinearRegression"
      name: "LinearRegression_Tuned"
      run_name: "LinearRegression"
      log_model_artifact: true
      register_model: false
      log_predictions: false
      log_interpretability_artifacts: true
      evaluate_on_test_set: false
      drop_multicollinear_cols: ["time"]
      training_params:
        n_jobs: -1
        fit_intercept: true
      cross_validation:
        enabled: true
        n_splits: 5

    Ridge:
      model_class: "Ridge"
      name: "Ridge_Tuned"
      run_name: "Ridge_Base"
      log_model_artifact: true
      register_model: false
      log_predictions: true
      log_interpretability_artifacts: true
      evaluate_on_test_set: false
      drop_multicollinear_cols: ["time"]
      training_params:
        alpha: 1.0
        fit_intercept: true
        solver: "auto"
        random_state: 42
      cross_validation:
        enabled: true
        n_splits: 5

    Lasso:
      model_class: "Lasso"
      name: "Lasso_Tuned"
      run_name: "Lasso_Base"
      log_model_artifact: true
      register_model: false
      log_predictions: true
      log_interpretability_artifacts: true
      evaluate_on_test_set: false
      drop_multicollinear_cols: ["time"]
      training_params:
        alpha: 1.0
        fit_intercept: true
        selection: "cyclic"
        random_state: 42
      cross_validation:
        enabled: true
        n_splits: 5

    ElasticNet:
      model_class: "ElasticNet"
      name: "ElasticNet_Tuned"
      run_name: "ElasticNet_Base"
      log_model_artifact: true
      register_model: false
      log_predictions: true
      log_interpretability_artifacts: true
      evaluate_on_test_set: false
      drop_multicollinear_cols: ["time"]
      training_params:
        alpha: 1.0
        l1_ratio: 0.5
        fit_intercept: true
        selection: "cyclic"
        random_state: 42
      cross_validation:
        enabled: true
        n_splits: 5

    # =================================================================
    # 2. Tree-Based Ensemble Models
    # =================================================================
    RandomForestRegressor:
      model_class: "RandomForestRegressor"
      name: "RFR_Tuned"
      run_name: "RFR_CV_Tuned_BakeOff"
      log_model_artifact: false
      register_model: false
      log_predictions: false
      log_interpretability_artifacts: true
      evaluate_on_test_set: false
      drop_multicollinear_cols: []
      training_params:
        n_estimators: 600
        max_depth: 14
        min_samples_split: 16
        min_samples_leaf: 4
        max_features: 0.5062662102018453
        random_state: 42
        n_jobs: -1
      cross_validation:
        enabled: true
        n_splits: 5

    XGBRegressor:
      model_class: "XGBRegressor"
      name: "XGBR_Tuned"
      run_name: "XBGR_CV_Tuned_BakeOff"
      log_model_artifact: true
      register_model: false
      log_predictions: true
      log_interpretability_artifacts: true
      evaluate_on_test_set: false
      drop_multicollinear_cols: []
      training_params:
        n_estimators: 100
        learning_rate: 0.3
        max_depth: 6
        subsample: 1.0
        colsample_bytree: 1.0
        gamma: 0
        reg_alpha: 0
        reg_lambda: 1
        random_state: 42
        n_jobs: -1
      cross_validation:
        enabled: true
        n_splits: 5

    LGBMRegressor:
      model_class: "LGBMRegressor"
      name: "LGBM_Tuned"
      run_name: "LGBMRegressor_Tuned"
      log_model_artifact: true
      register_model: false
      log_predictions: true
      log_interpretability_artifacts: true
      evaluate_on_test_set: false
      drop_multicollinear_cols: []
      training_params:
        n_estimators: 100
        learning_rate: 0.1
        num_leaves: 31
        max_depth: -1
        subsample: 1.0
        colsample_bytree: 1.0
        reg_alpha: 0.0
        reg_lambda: 0.0
        random_state: 42
        n_jobs: -1
      cross_validation:
        enabled: true
        n_splits: 5

    # =================================================================
    # 3. Other Models
    # =================================================================
    SGDRegressor:
      model_class: "SGDRegressor"
      name: "SGD_Tuned"
      run_name: "SGDRegressor_Tuned"
      log_model_artifact: true
      register_model: false
      log_predictions: true
      log_interpretability_artifacts: true
      evaluate_on_test_set: false
      drop_multicollinear_cols: ["time"]
      training_params:
        loss: "squared_error"
        penalty: "l2"
        alpha: 0.0001
        max_iter: 1000
        random_state: 42
      cross_validation:
        enabled: true
        n_splits: 5

    SVR:
      model_class: "SVR"
      name: "SVR_Tuned"
      run_name: "SVR_Tuned"
      log_model_artifact: true
      register_model: false
      log_predictions: true
      log_interpretability_artifacts: true
      evaluate_on_test_set: false
      drop_multicollinear_cols: []
      training_params:
        kernel: "rbf"
        C: 1.0
        gamma: "scale"
        epsilon: 0.1
      cross_validation:
        enabled: true
        n_splits: 5